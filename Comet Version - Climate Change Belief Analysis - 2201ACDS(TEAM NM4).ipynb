{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-XweBu-_x9Vj"
   },
   "source": [
    "## Introduction to Comet ML  \n",
    "\n",
    "Comet is a great tool for model versioning and experimentation as it records the parameters and conditions from each of your experiements- allowing you to reproduce your results, or go back to a previous version of your experiment.  \n",
    "\n",
    "To create an account, visit https://www.comet.ml/  \n",
    "Follow the instructions for a single user account. Once that is created, you will see a project folder. That is where the records of your experiments can be viewed. \n",
    "\n",
    "Comet has an abundance of tutorials and scripts, we're just going to run through this notebook to get you started on the right track. For this illustration, we will be using one of the examples found on the Comet ML GitHub repo.\n",
    "\n",
    "To begin with, you should install as illustrated below if you don't already have it. *Always import Experiment at the top of your notebook/script.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "3Wd_iEgx6j2w",
    "outputId": "d4322780-007b-432b-82bf-093a48e93428"
   },
   "outputs": [],
   "source": [
    "!pip install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "3jhxZfPg6qxH"
   },
   "outputs": [],
   "source": [
    "from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cObkea-S7Y85"
   },
   "source": [
    "You will see an API key button at the top of the page when you click on an experiment- use this key as illustrated below to link your current workspace to comet. (If a project is empty, the code below will autogenerate for you on the project page, just copy and paste it in here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "S5cRjXOH7aTX",
    "outputId": "9de3fcce-d970-4393-f264-793fb2d4ac74"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/daniel-ifediba/climate-change-belief-analysis-2201acds-team-nm4/ce50db2192284febad6785503dbf443f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setting the API key (saved as environment variable)\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    api_key=\"769nn1WRQ3JOmstx7e82dAUlZ\",\n",
    "    project_name=\"climate-change-belief-analysis-2201acds-team-nm4\",\n",
    "    workspace=\"daniel-ifediba\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dN3PMg07s0Q"
   },
   "source": [
    "Import the rest of your necessary libraries as you usually would. For this demonstration we will be using the breast cancer dataset for classification so we will also import that from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Q53Mocnc79cF"
   },
   "outputs": [],
   "source": [
    "import warnings # to filter out warnings in the jupyter notebook\n",
    "warnings.filterwarnings('ignore') # we will ignore all warning and not show them\n",
    "\n",
    "import re                                  \n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "                          \n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer, TreebankWordTokenizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "olkD6zuo_VI9",
    "outputId": "5f6cd772-b2ec-4a7f-971d-4e3b71e785b8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625221</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126103</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698562</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573736</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466954</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                            message\n",
       "tweetid                                                              \n",
       "625221           1  PolySciMajor EPA chief doesn't think carbon di...\n",
       "126103           1  It's not like we lack evidence of anthropogeni...\n",
       "698562           2  RT @RawStory: Researchers say we have three ye...\n",
       "573736           1  #TodayinMaker# WIRED : 2016 was a pivotal year...\n",
       "466954           1  RT @SoyNovioDeTodas: It's 2016, and a racist, ..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a look at your dataset\n",
    "df = pd.read_csv('./data/train.csv', index_col='tweetid', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick a class size of roughly half the size of the largest size\n",
    "class_size = 5000\n",
    "# Let's list the target labels\n",
    "labels_counts = df['sentiment'].value_counts().to_dict()\n",
    "\n",
    "resampled_classes = []\n",
    "\n",
    "# For each label\n",
    "for label, label_size in labels_counts.items():\n",
    "    # If label_size < class size then set replace to True to upsample, else False to downsample\n",
    "    if label_size < class_size:\n",
    "        # Upsample\n",
    "        replacement = True # sample with replacement (we need to duplicate observations)\n",
    "    else:\n",
    "        # Downsample\n",
    "        replacement = False # sample with replacement (we need to duplicate observations)\n",
    "    label_data = df[df['sentiment'] == label]\n",
    "    label_resampled = resample(label_data,\n",
    "                               replace=replacement, # sample without replacement (no need for duplicate observations)\n",
    "                               n_samples=class_size, # number of desired samples\n",
    "                               random_state=27) # reproducible results\n",
    "\n",
    "    resampled_classes.append(label_resampled)\n",
    "\n",
    "resampled_data = pd.concat(resampled_classes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to strip emojis from the tweets\n",
    "\n",
    "def remove_emoji(text):\n",
    "    EMOJI_PATTERN = re.compile(\n",
    "        \"([\"\n",
    "        \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\"\n",
    "        \"])\"\n",
    "    )\n",
    "    text = re.sub(EMOJI_PATTERN,  '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_preprocessor(tweet):\n",
    "    # remove the old style retweet text \"RT\"\n",
    "    tweet_clean = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "    # remove hashtags. We have to be careful here not to remove \n",
    "    # the whole hashtag because text of hashtags contains huge information. \n",
    "    # only remove the hash # sign from the word\n",
    "    tweet_clean = re.sub(r'#', '', tweet_clean)\n",
    "\n",
    "    # remove hyperlinks\n",
    "    tweet_clean = re.sub(\n",
    "        r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "        ,r'url-web',\n",
    "        tweet_clean)\n",
    "\n",
    "    # remove single numeric terms in the tweet. \n",
    "    tweet_clean = re.sub(r'\\s[0-9]+\\s', '', tweet_clean)\n",
    "\n",
    "    # remove emojis from in the tweet\n",
    "    tweet_clean = remove_emoji(tweet_clean)\n",
    "\n",
    "    # remove punctions from the tweet\n",
    "    tweet_clean = ''.join([l for l in tweet_clean if l not in string.punctuation])\n",
    "\n",
    "    # convert tweet to lowercase and return it\n",
    "    tweet_clean = tweet_clean.lower()\n",
    "    \n",
    "    # tokenize the tweet\n",
    "    tokenizer = TweetTokenizer() #Instantiate the tokenizer class\n",
    "    tweet_tokens = tokenizer.tokenize(tweet_clean)\n",
    "    \n",
    "    # remove stop words\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    tweet_tokens_without_stopwords = [t for t in tweet_tokens if t not in stopwords_english]\n",
    "    \n",
    "    # stem the tweet\n",
    "    #stemmer = PorterStemmer()\n",
    "    #tweet_stems = ' '.join([stemmer.stem(t) for t in tweet_tokens])\n",
    "    \n",
    "    # stem the tweet\n",
    "    lemma = WordNetLemmatizer()\n",
    "    tweet_stems = ' '.join([lemma.lemmatize(t) for t in tweet_tokens])\n",
    "    \n",
    "    return tweet_stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the labels and targets\n",
    "X = resampled_data['message']\n",
    "y = resampled_data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer( # Instantiate the object\n",
    "    preprocessor=tweet_preprocessor,\n",
    "    min_df=2, # with min_df of 2 for bag of words\n",
    "    ngram_range=(1,2) # with ngram_range of (1,2) for bag of words\n",
    ") \n",
    "vectorizer.fit(X) #build vocabulary for training\n",
    "X_tokenized = vectorizer.transform(X) #encode the text data \n",
    "\n",
    "# scale the encoded text data \n",
    "transformer = TfidfTransformer() # Instantiate the object\n",
    "X_trans = transformer.fit_transform(X_tokenized) # Transform the tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_KDcC6O_uon"
   },
   "source": [
    "Split your data into train and test sets, keep in mind that you need to set a random state for your results to be reproduced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yHBLubxt_b2t"
   },
   "outputs": [],
   "source": [
    "#Split the labels and target into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_trans, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93jtvJoIGxbK"
   },
   "source": [
    "## GridSearch \n",
    "\n",
    "For this example we've used a gridsearch but you may use a model with default parameters or your own parameters too- Just remember to add/remove the neccesary data when you are logging your parameters at the end of the experiment.\n",
    "\n",
    "The `param_grid` variable contains the 'C' values we want our gridsearch to iterate through.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "vjsyVrHF_kHR"
   },
   "outputs": [],
   "source": [
    "# Create a list containing the various models to evaluate\n",
    "# include the parameters we are interested to tune for each model\n",
    "models = [\n",
    "    ## define the mode MultinomialNB Classifier\n",
    "    {\n",
    "        'model': MultinomialNB(), # instantiate the model\n",
    "        'param_grid': { # set hyper parameters for model tuning\n",
    "            'alpha': [0.0001, 0.001, 0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "        ## define the model Logistic Regression Classifier\n",
    "    {  \n",
    "        'model': LogisticRegression(), # instantiate the model\n",
    "        'param_grid': { # set hyper parameters for model tuning\n",
    "            'C' : [0.1, 1],\n",
    "            'solver' : ['liblinear'],\n",
    "            'max_iter' : [100, 1000]\n",
    "        }\n",
    "    }\n",
    "]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting MultinomialNB model....\n",
      "Finished fitting and testing MultinomialNB(alpha=0.1)\n",
      "Fitting LogisticRegression model....\n",
      "Finished fitting and testing LogisticRegression(C=1, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "for item in models:\n",
    "    model = item['model'] # get the model object instance\n",
    "    param_grid = item['param_grid'] # get the parameters that will be used for tuning\n",
    "    # define the grid instance\n",
    "    grid =  GridSearchCV(\n",
    "        model, # model instance\n",
    "        param_grid = param_grid, # hyper-parameters\n",
    "        cv = 10, # cross-validation splitting\n",
    "        scoring = 'f1_weighted', # f1_scoring\n",
    "        refit=True\n",
    "    )\n",
    "    print(f'Fitting {model.__class__.__name__} model....')\n",
    "    grid.fit(X_train, y_train) # fit the grid to the X-train and the y_train\n",
    "    y_pred = grid.predict(X_test) # Predict values for X_test\n",
    "\n",
    "    # Saving each metric to add to a dictionary for logging\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(f'Finished fitting and testing {grid.best_estimator_}')\n",
    "    # Create dictionaries for the data we want to log\n",
    "\n",
    "    params = {\"random_state\": 42,\n",
    "              \"model_type\": model.__class__.__name__,\n",
    "              \"vectorizer\": 'CounterVectorizer',\n",
    "              \"transformer\": \"TfidfTransformer\",\n",
    "              \"param_grid\": str(param_grid),\n",
    "              \"stratify\": True\n",
    "              }\n",
    "    metrics = {\"f1\": f1,\n",
    "               \"recall\": recall,\n",
    "               \"precision\": precision\n",
    "               }\n",
    "    # Log our parameters and results\n",
    "    experiment.log_parameters(params)\n",
    "    experiment.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuUPB_amTU-0"
   },
   "source": [
    "If you're using comet within a jupyter notebook, it's important to end your experiment when you've finished as illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "CbQ3tKA-G6rW",
    "outputId": "d5818c72-cc5b-4c51-d4ef-cea92962f19f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/daniel-ifediba/climate-change-belief-analysis-2201acds-team-nm4/ce50db2192284febad6785503dbf443f\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     f1 [2]        : (0.8764811128651229, 0.9085913574572091)\n",
      "COMET INFO:     precision [2] : (0.8778590159627107, 0.9095206009759094)\n",
      "COMET INFO:     recall [2]    : (0.878, 0.9085)\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     C                            : 1\n",
      "COMET INFO:     alpha                        : 0.1\n",
      "COMET INFO:     analyzer                     : word\n",
      "COMET INFO:     binary                       : False\n",
      "COMET INFO:     class_prior                  : 1\n",
      "COMET INFO:     class_weight                 : 1\n",
      "COMET INFO:     cv                           : 10\n",
      "COMET INFO:     decode_error                 : strict\n",
      "COMET INFO:     dtype                        : <class 'numpy.int64'>\n",
      "COMET INFO:     dual                         : False\n",
      "COMET INFO:     encoding                     : utf-8\n",
      "COMET INFO:     error_score                  : nan\n",
      "COMET INFO:     estimator                    : LogisticRegression()\n",
      "COMET INFO:     estimator__C                 : 1.0\n",
      "COMET INFO:     estimator__alpha             : 1.0\n",
      "COMET INFO:     estimator__class_prior       : 1\n",
      "COMET INFO:     estimator__class_weight      : 1\n",
      "COMET INFO:     estimator__dual              : False\n",
      "COMET INFO:     estimator__fit_intercept     : True\n",
      "COMET INFO:     estimator__fit_prior         : True\n",
      "COMET INFO:     estimator__intercept_scaling : 1\n",
      "COMET INFO:     estimator__l1_ratio          : 1\n",
      "COMET INFO:     estimator__max_iter          : 100\n",
      "COMET INFO:     estimator__multi_class       : auto\n",
      "COMET INFO:     estimator__n_jobs            : 1\n",
      "COMET INFO:     estimator__penalty           : l2\n",
      "COMET INFO:     estimator__random_state      : 1\n",
      "COMET INFO:     estimator__solver            : lbfgs\n",
      "COMET INFO:     estimator__tol               : 0.0001\n",
      "COMET INFO:     estimator__verbose           : 0\n",
      "COMET INFO:     estimator__warm_start        : False\n",
      "COMET INFO:     fit_intercept                : True\n",
      "COMET INFO:     fit_prior                    : True\n",
      "COMET INFO:     input                        : content\n",
      "COMET INFO:     intercept_scaling            : 1\n",
      "COMET INFO:     l1_ratio                     : 1\n",
      "COMET INFO:     lowercase                    : True\n",
      "COMET INFO:     max_df                       : 1.0\n",
      "COMET INFO:     max_features                 : 1\n",
      "COMET INFO:     max_iter                     : 100\n",
      "COMET INFO:     min_df                       : 2\n",
      "COMET INFO:     model_type                   : LogisticRegression\n",
      "COMET INFO:     multi_class                  : auto\n",
      "COMET INFO:     n_jobs                       : 1\n",
      "COMET INFO:     neg_label                    : 0\n",
      "COMET INFO:     ngram_range                  : (1, 2)\n",
      "COMET INFO:     norm                         : l2\n",
      "COMET INFO:     param_grid                   : {'C': [0.1, 1], 'solver': ['liblinear'], 'max_iter': [100, 1000]}\n",
      "COMET INFO:     penalty                      : l2\n",
      "COMET INFO:     pos_label                    : 1\n",
      "COMET INFO:     pre_dispatch                 : 2*n_jobs\n",
      "COMET INFO:     preprocessor                 : <function tweet_preprocessor at 0x0000001DF0599280>\n",
      "COMET INFO:     random_state                 : 42\n",
      "COMET INFO:     refit                        : True\n",
      "COMET INFO:     return_train_score           : False\n",
      "COMET INFO:     scoring                      : f1_weighted\n",
      "COMET INFO:     smooth_idf                   : True\n",
      "COMET INFO:     solver                       : liblinear\n",
      "COMET INFO:     sparse_output                : False\n",
      "COMET INFO:     stop_words                   : 1\n",
      "COMET INFO:     stratify                     : True\n",
      "COMET INFO:     strip_accents                : 1\n",
      "COMET INFO:     sublinear_tf                 : False\n",
      "COMET INFO:     token_pattern                : (?u)\\b\\w\\w+\\b\n",
      "COMET INFO:     tokenizer                    : 1\n",
      "COMET INFO:     tol                          : 0.0001\n",
      "COMET INFO:     transformer                  : TfidfTransformer\n",
      "COMET INFO:     use_idf                      : True\n",
      "COMET INFO:     vectorizer                   : CounterVectorizer\n",
      "COMET INFO:     verbose                      : 0\n",
      "COMET INFO:     vocabulary                   : 1\n",
      "COMET INFO:     warm_start                   : False\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     conda-info          : 1\n",
      "COMET INFO:     conda-specification : 1\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET ERROR: Error sending a notification, make sure you have opted-in for notifications\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: All files uploaded, waiting for confirmation they have been all received\n"
     ]
    }
   ],
   "source": [
    "experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXuUORTEooIX"
   },
   "source": [
    "## Display  \n",
    "\n",
    "Running `experiment.display()` will show you your experiments comet.ml page inside your notebook as illustrated below. You can do this immediately after an experiment is run, and logged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 821
    },
    "id": "B-5ZmY-ZHFRf",
    "outputId": "4ea3e2c5-783d-49af-e71e-aaa59e63ea18"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800px\"\n",
       "            src=\"https://www.comet.ml/daniel-ifediba/climate-change-belief-analysis-2201acds-team-nm4/ce50db2192284febad6785503dbf443f\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1df4ea1f70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fupy3YeZolRA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "sklearn_comet_starter_notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
